# âš¡ Powerwatch: Automated NEM Demand Monitoring Pipeline

Powerwatch is an automated data pipeline that:
- Downloads 5-minute operational demand data from AEMO's NEMWeb
- Cleans and processes the data
- Uploads it to AWS S3
- Loads it into Amazon Redshift
- Runs automated data quality checks using Soda Cloud

## ğŸ“¦ Features

- ğŸ”„ End-to-end automation with a single script (`run_pipeline.py`)
- â˜ï¸ Cloud-native stack: AWS S3 + Redshift + Soda Cloud
- âœ… Data quality checks with alerts and monitoring
- ğŸ›  Modular scripts for each pipeline stage

---

## ğŸ—‚ Repo Structure

```
powerwatch/
â”œâ”€â”€ environment.yml            # Conda environment definition
â”œâ”€â”€ run_pipeline.py            # Master script to run the entire pipeline
â”œâ”€â”€ scripts/                   # Individual pipeline stages
â”‚   â”œâ”€â”€ download_data.py
â”‚   â”œâ”€â”€ clean_data.py
â”‚   â”œâ”€â”€ upload_to_s3.py
â”‚   â”œâ”€â”€ copy_to_redshift.py
â”‚   â””â”€â”€ run_soda_checks.py
â”œâ”€â”€ soda/                      # Soda configuration
â”‚   â”œâ”€â”€ soda_cloud.yml
â”‚   â”œâ”€â”€ warehouse.yml
â”‚   â””â”€â”€ soda_checks.yml
â””â”€â”€ data/                      # Raw and intermediate data files
```

---

## ğŸš€ How to Run It

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/powerwatch.git
cd powerwatch
```

### 2. Set Up Environment

```bash
conda env create -f environment.yml
conda activate soda310
```

### 3. Configure Secrets

Edit your `soda/soda_cloud.yml` and scripts to add:
- âœ… Soda API key
- âœ… AWS credentials
- âœ… Redshift IAM role and cluster details

### 4. Run the Pipeline

```bash
python run_pipeline.py
```

---

## ğŸ“Š Soda Cloud

Your data is validated with [Soda Cloud](https://beta.soda.io), which shows:
- Row counts
- Missing values
- Failed thresholds
- Anomaly flags

---

## ğŸ“Œ Requirements

- Python 3.10
- AWS account with:
  - S3 bucket
  - Redshift Serverless
  - IAM role for COPY
- Soda Cloud account

---

Made by Nam Nguyen | 2025
